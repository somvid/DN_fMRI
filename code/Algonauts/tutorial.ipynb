{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d0dee8-c65d-4159-b5e4-3c55cd542393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from Algonauts2021_devkit.feature_extraction.alexnet import *\n",
    "import numpy as np\n",
    "import urllib\n",
    "import torch\n",
    "import cv2\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as trn\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.autograd import Variable as V\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from decord import VideoReader\n",
    "from decord import cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0fa8f8d-c043-4cbf-9779-2b7d201aad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# Python RNG\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "def load_alexnet(model_checkpoints):\n",
    "    \"\"\"This function initializes an Alexnet and load\n",
    "    its weights from a pretrained model\n",
    "    ----------\n",
    "    model_checkpoints : str\n",
    "        model checkpoints location.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model\n",
    "        pytorch model of alexnet\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    model = alexnet()\n",
    "    model_file = model_checkpoints\n",
    "    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "    model_dict =[\"conv1.0.weight\", \"conv1.0.bias\", \"conv2.0.weight\", \"conv2.0.bias\", \"conv3.0.weight\", \"conv3.0.bias\", \"conv4.0.weight\", \"conv4.0.bias\", \"conv5.0.weight\", \"conv5.0.bias\", \"fc6.1.weight\", \"fc6.1.bias\", \"fc7.1.weight\", \"fc7.1.bias\", \"fc8.1.weight\", \"fc8.1.bias\"]\n",
    "    state_dict={}\n",
    "    i=0\n",
    "    for k,v in checkpoint.items():\n",
    "        state_dict[model_dict[i]] =  v\n",
    "        i+=1\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def sample_video_from_mp4(file, num_frames=16):\n",
    "    \"\"\"This function takes a mp4 video file as input and returns\n",
    "    a list of uniformly sampled frames (PIL Image).\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        path to mp4 video file\n",
    "    num_frames : int\n",
    "        how many frames to select using uniform frame sampling.\n",
    "    Returns\n",
    "    -------\n",
    "    images: list of PIL Images\n",
    "    num_frames: int\n",
    "        number of frames extracted\n",
    "    \"\"\"\n",
    "    images = list()\n",
    "    vr = VideoReader(file, ctx=cpu(0))\n",
    "    total_frames = len(vr)\n",
    "    indices = np.linspace(0,total_frames-1,num_frames,dtype=np.int)\n",
    "    for seg_ind in indices:\n",
    "        images.append(Image.fromarray(vr[seg_ind].asnumpy()))\n",
    "    return images,num_frames\n",
    "\n",
    "def get_activations_and_save(model, video_list, activations_dir):\n",
    "    \"\"\"This function generates Alexnet features and save them in a specified directory.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        pytorch model : alexnet.\n",
    "    video_list : list\n",
    "        the list contains path to all videos.\n",
    "    activations_dir : str\n",
    "        save path for extracted features.\n",
    "    \"\"\"\n",
    "\n",
    "    resize_normalize = trn.Compose([\n",
    "            trn.Resize((224,224)),\n",
    "            trn.ToTensor(),\n",
    "            trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    for video_file in tqdm(video_list):\n",
    "        vid,num_frames = sample_video_from_mp4(video_file)\n",
    "        video_file_name = os.path.split(video_file)[-1].split(\".\")[0]\n",
    "        activations = []\n",
    "        for frame,img in enumerate(vid):\n",
    "            input_img = V(resize_normalize(img).unsqueeze(0))\n",
    "            if torch.cuda.is_available():\n",
    "                input_img=input_img.cuda()\n",
    "            x = model.forward(input_img)\n",
    "            for i,feat in enumerate(x):\n",
    "                if frame==0:\n",
    "                    activations.append(feat.data.cpu().numpy().ravel())\n",
    "                else:\n",
    "                    activations[i] =  activations[i] + feat.data.cpu().numpy().ravel()\n",
    "        for layer in range(len(activations)):\n",
    "            save_path = os.path.join(activations_dir, video_file_name+\"_\"+\"layer\" + \"_\" + str(layer+1) + \".npy\")\n",
    "            avg_layer_activation = activations[layer]/float(num_frames)\n",
    "            np.save(save_path,avg_layer_activation)\n",
    "\n",
    "\n",
    "\n",
    "def do_PCA_and_save(activations_dir, save_dir):\n",
    "    \"\"\"This function preprocesses Neural Network features using PCA and save the results\n",
    "    in  a specified directory\n",
    ".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    activations_dir : str\n",
    "        save path for extracted features.\n",
    "    save_dir : str\n",
    "        save path for extracted PCA features.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    layers = ['layer_1','layer_2','layer_3','layer_4','layer_5','layer_6','layer_7','layer_8']\n",
    "    n_components = 100\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    for layer in tqdm(layers):\n",
    "        activations_file_list = glob.glob(activations_dir +'/*'+layer+'.npy')\n",
    "        activations_file_list.sort()\n",
    "        feature_dim = np.load(activations_file_list[0])\n",
    "        x = np.zeros((len(activations_file_list),feature_dim.shape[0]))\n",
    "        for i,activation_file in enumerate(activations_file_list):\n",
    "            temp = np.load(activation_file)\n",
    "            x[i,:] = temp\n",
    "        x_train = x[:1000,:]\n",
    "        x_test = x[1000:,:]\n",
    "\n",
    "        start_time = time.time()\n",
    "        x_test = StandardScaler().fit_transform(x_test)\n",
    "        x_train = StandardScaler().fit_transform(x_train)\n",
    "        ipca = PCA(n_components=n_components,random_state=seed)\n",
    "        ipca.fit(x_train)\n",
    "\n",
    "        x_train = ipca.transform(x_train)\n",
    "        x_test = ipca.transform(x_test)\n",
    "        train_save_path = os.path.join(save_dir,\"train_\"+layer)\n",
    "        test_save_path = os.path.join(save_dir,\"test_\"+layer)\n",
    "        np.save(train_save_path,x_train)\n",
    "        np.save(test_save_path,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "160d2078-3b3e-44d3-b983-aa2bb343f4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgumentParser(prog='ipykernel_launcher.py', usage=None, description='Feature Extraction from Alexnet and preprocessing using PCA', formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Feature Extraction from Alexnet and preprocessing using PCA')\n",
    "parser.add_argument('-vdir','--video_data_dir', help='video data directory',default = './AlgonautsVideos268_All_30fpsmax/', type=str)\n",
    "parser.add_argument('-sdir','--save_dir', help='saves processed features',default = './alexnet/', type=str)\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1244cd5f-35c9-4364-a762-2e8407742fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Videos:  1102\n",
      "-------------Saving activations ----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1102 [00:00<?, ?it/s]C:\\Users\\Dasom\\AppData\\Local\\Temp/ipykernel_22180/426207514.py:60: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = np.linspace(0,total_frames-1,num_frames,dtype=np.int)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1102/1102 [09:03<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------performing  PCA----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [01:43<00:00, 12.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='Feature Extraction from Alexnet and preprocessing using PCA')\n",
    "# parser.add_argument('-vdir','--video_data_dir', help='video data directory',default = './AlgonautsVideos268_All_30fpsmax/', type=str)\n",
    "# parser.add_argument('-sdir','--save_dir', help='saves processed features',default = './alexnet/', type=str)\n",
    "# args = vars(parser.parse_args())\n",
    "\n",
    "save_dir='./alexnet/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "video_dir = './AlgonautsVideos268_All_30fpsmax/'\n",
    "video_list = glob.glob(video_dir + '/*.mp4')\n",
    "video_list.sort()\n",
    "print('Total Number of Videos: ', len(video_list))\n",
    "\n",
    "# load Alexnet\n",
    "# Download pretrained Alexnet from:\n",
    "# https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\n",
    "# and save in the current directory\n",
    "checkpoint_path = \"./alexnet.pth\"\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    url = \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\"\n",
    "    urllib.request.urlretrieve(url, \"./alexnet.pth\")\n",
    "model = load_alexnet(checkpoint_path)\n",
    "\n",
    "# get and save activations\n",
    "activations_dir = os.path.join(save_dir)\n",
    "if not os.path.exists(activations_dir):\n",
    "    os.makedirs(activations_dir)\n",
    "print(\"-------------Saving activations ----------------------------\")\n",
    "get_activations_and_save(model, video_list, activations_dir)\n",
    "\n",
    "# preprocessing using PCA and save\n",
    "pca_dir = os.path.join(save_dir, 'pca_100')\n",
    "print(\"-------------performing  PCA----------------------------\")\n",
    "do_PCA_and_save(activations_dir, pca_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "741aeb51-48da-4c3c-978d-7fa6b5753dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46656,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./alexnet/1102_meta_R-5602303_250_layer_1.npy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3adce42-16f1-4669-b936-0e68ba039100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./participants_data_v2021/mini_track/sub01/EBA.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ac484e8-656e-4425-9233-5599de15a075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.010660860410681625, 0.842243696794278)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(data['train'][0][0], data['train'][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "438dc90d-651f-4d8e-9b51-b1bc1983a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "import itertools\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from tqdm import tqdm\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from Algonauts2021_devkit.utils.ols import vectorized_correlation,OLS_pytorch\n",
    "from Algonauts2021_devkit.utils.helper import save_dict,load_dict, saveasnii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "557c06d2-fa85-494b-bba5-ae183c87bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(activations_dir, layer_name):\n",
    "    \"\"\"This function loads neural network features/activations (preprocessed using PCA) into a\n",
    "    numpy array according to a given layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    activations_dir : str\n",
    "        Path to PCA processed Neural Network features\n",
    "    layer_name : str\n",
    "        which layer of the neural network to load,\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_activations : np.array\n",
    "        matrix of dimensions #train_vids x #pca_components\n",
    "        containing activations of train videos\n",
    "    test_activations : np.array\n",
    "        matrix of dimensions #test_vids x #pca_components\n",
    "        containing activations of test videos\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    train_file = os.path.join(activations_dir,\"train_\" + layer_name + \".npy\")\n",
    "    test_file = os.path.join(activations_dir,\"test_\" + layer_name + \".npy\")\n",
    "    train_activations = np.load(train_file)\n",
    "    test_activations = np.load(test_file)\n",
    "    scaler = StandardScaler()\n",
    "    train_activations = scaler.fit_transform(train_activations)\n",
    "    test_activations = scaler.fit_transform(test_activations)\n",
    "\n",
    "    return train_activations, test_activations\n",
    "\n",
    "def get_fmri(fmri_dir, ROI):\n",
    "    \"\"\"This function loads fMRI data into a numpy array for to a given ROI.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fmri_dir : str\n",
    "        path to fMRI data.\n",
    "    ROI : str\n",
    "        name of ROI.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        matrix of dimensions #train_vids x #repetitions x #voxels\n",
    "        containing fMRI responses to train videos of a given ROI\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Loading ROI data\n",
    "    ROI_file = os.path.join(fmri_dir, ROI + \".pkl\")\n",
    "    ROI_data = load_dict(ROI_file)\n",
    "\n",
    "    # averaging ROI data across repetitions\n",
    "    ROI_data_train = np.mean(ROI_data[\"train\"], axis = 1)\n",
    "    if ROI == \"WB\":\n",
    "        voxel_mask = ROI_data['voxel_mask']\n",
    "        return ROI_data_train, voxel_mask\n",
    "\n",
    "    return ROI_data_train\n",
    "\n",
    "def predict_fmri_fast(train_activations, test_activations, train_fmri,use_gpu=False):\n",
    "    \"\"\"This function fits a linear regressor using train_activations and train_fmri,\n",
    "    then returns the predicted fmri_pred_test using the fitted weights and\n",
    "    test_activations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_activations : np.array\n",
    "        matrix of dimensions #train_vids x #pca_components\n",
    "        containing activations of train videos.\n",
    "    test_activations : np.array\n",
    "        matrix of dimensions #test_vids x #pca_components\n",
    "        containing activations of test videos\n",
    "    train_fmri : np.array\n",
    "        matrix of dimensions #train_vids x  #voxels\n",
    "        containing fMRI responses to train videos\n",
    "    use_gpu : bool\n",
    "        Description of parameter `use_gpu`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fmri_pred_test: np.array\n",
    "        matrix of dimensions #test_vids x  #voxels\n",
    "        containing predicted fMRI responses to test videos .\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    reg = OLS_pytorch(use_gpu)\n",
    "    reg.fit(train_activations,train_fmri.T)\n",
    "    fmri_pred_test = reg.predict(test_activations)\n",
    "    return fmri_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0c8d3a1-06f5-4283-802f-e27c8d513191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROi is :  FFA\n",
      "number of voxels is  68\n",
      "----------------------------------------------------------------------------\n",
      "Mean correlation for ROI :  FFA in  sub01  is : 0.054\n",
      "----------------------------------------------------------------------------\n",
      "ROI done :  FFA\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='Encoding model analysis for Algonauts 2021')\n",
    "# parser.add_argument('-rd','--result_dir', help='saves predicted fMRI activity',default = './results', type=str)\n",
    "# parser.add_argument('-ad','--activation_dir',help='directory containing DNN activations',default = './alexnet/', type=str)\n",
    "# parser.add_argument('-model','--model',help='model name under which predicted fMRI activity will be saved', default = 'alexnet_devkit', type=str)\n",
    "# parser.add_argument('-l','--layer',help='layer from which activations will be used to train and predict fMRI activity', default = 'layer_5', type=str)\n",
    "# parser.add_argument('-sub','--sub',help='subject number from which real fMRI data will be used', default = 'sub04', type=str)\n",
    "# parser.add_argument('-r','--roi',help='brain region, from which real fMRI data will be used', default = 'EBA', type=str)\n",
    "# parser.add_argument('-m','--mode',help='test or val, val returns mean correlation by using 10% of training data for validation', default = 'val', type=str)\n",
    "# parser.add_argument('-fd','--fmri_dir',help='directory containing fMRI activity', default = './participants_data_v2021', type=str)\n",
    "# parser.add_argument('-v','--visualize',help='visualize whole brain results in MNI space or not', default = True, type=bool)\n",
    "# parser.add_argument('-b', '--batch_size',help=' number of voxel to fit at one time in case of memory constraints', default = 1000, type=int)\n",
    "# args = vars(parser.parse_args())\n",
    "\n",
    "\n",
    "mode = 'val'\n",
    "sub = 'sub01'\n",
    "ROI = 'FFA'\n",
    "model = 'Algonauts2021_devkit/'\n",
    "layer = 'layer_1'\n",
    "visualize_results = True\n",
    "batch_size = 1000 # number of voxel to fit at one time in case of memory constraints\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "else:\n",
    "    use_gpu = False\n",
    "\n",
    "if ROI == \"WB\":\n",
    "    track = \"full_track\"\n",
    "else:\n",
    "    track = \"mini_track\"\n",
    "\n",
    "activation_dir = './alexnet/pca_100'\n",
    "fmri_dir = './participants_data_v2021'\n",
    "\n",
    "sub_fmri_dir = os.path.join(fmri_dir, track, sub)\n",
    "results_dir = './result'\n",
    "\n",
    "print(\"ROi is : \", ROI)\n",
    "\n",
    "train_activations,test_activations = get_activations(activation_dir, layer)\n",
    "if track == \"full_track\":\n",
    "    fmri_train_all,voxel_mask = get_fmri(sub_fmri_dir,ROI)\n",
    "else:\n",
    "    fmri_train_all = get_fmri(sub_fmri_dir,ROI)\n",
    "num_voxels = fmri_train_all.shape[1]\n",
    "if mode == 'val':\n",
    "    # Here as an example we use first 900 videos as training and rest of the videos as validation\n",
    "    test_activations = train_activations[900:,:]\n",
    "    train_activations = train_activations[:900,:]\n",
    "    fmri_train = fmri_train_all[:900,:]\n",
    "    fmri_test = fmri_train_all[900:,:]\n",
    "    pred_fmri = np.zeros_like(fmri_test)\n",
    "    pred_fmri_save_path = os.path.join(results_dir, ROI + '_val.npy')\n",
    "else:\n",
    "    fmri_train = fmri_train_all\n",
    "    num_test_videos = 102\n",
    "    pred_fmri = np.zeros((num_test_videos,num_voxels))\n",
    "    pred_fmri_save_path = os.path.join(results_dir, ROI + '_test.npy')\n",
    "\n",
    "\n",
    "print(\"number of voxels is \", num_voxels)\n",
    "iter = 0\n",
    "while iter < num_voxels-batch_size:\n",
    "    pred_fmri[:,iter:iter+batch_size] = predict_fmri_fast(train_activations,test_activations,fmri_train[:,iter:iter+batch_size], use_gpu = use_gpu)\n",
    "    iter = iter+batch_size\n",
    "    print((100*iter)//num_voxels,\" percent complete\")\n",
    "pred_fmri[:,iter:] = predict_fmri_fast(train_activations,test_activations,fmri_train[:,iter:iter+batch_size], use_gpu = use_gpu)\n",
    "\n",
    "if mode == 'val':\n",
    "    score = vectorized_correlation(fmri_test,pred_fmri)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"Mean correlation for ROI : \",ROI, \"in \",sub, \" is :\", round(score.mean(), 3))\n",
    "\n",
    "    # result visualization for whole brain (full_track)\n",
    "    if track == \"full_track\" and visualize_results:\n",
    "        visual_mask_3D = np.zeros((78,93,71))\n",
    "        visual_mask_3D[voxel_mask==1]= score\n",
    "        brain_mask = './Algonauts2021_devkit/example.nii'\n",
    "        nii_save_path =  os.path.join(results_dir, ROI + '_val.nii')\n",
    "        saveasnii(brain_mask,nii_save_path,visual_mask_3D)\n",
    "        view = plotting.view_img_on_surf(nii_save_path, threshold=None, surf_mesh='fsaverage',\\\n",
    "                                        title = 'Correlation for sub' + sub, colorbar=False)\n",
    "        view_save_path = os.path.join(results_dir,ROI + '_val.html')\n",
    "        view.save_as_html(view_save_path)\n",
    "        print(\"Results saved in this directory: \", results_dir)\n",
    "        view.open_in_browser()\n",
    "\n",
    "\n",
    "np.save(pred_fmri_save_path, pred_fmri)\n",
    "\n",
    "\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(\"ROI done : \", ROI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
